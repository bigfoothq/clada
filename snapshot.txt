
=== START FILE: ./proj/test-data/execute.md ===
# Execute Tests

## basic operations

### 001-single-file-create

```sh sham
#!SHAM [@three-char-SHA-256: abc]
action = "file_write"
path = "/tmp/test.txt"
content = "hello world"
#!END_SHAM_abc
```

```json
{
  "success": true,
  "totalBlocks": 1,
  "executedActions": 1,
  "results": [{
    "seq": 1,
    "blockId": "abc",
    "action": "file_write",
    "params": {
      "action": "file_write",
      "path": "/tmp/test.txt",
      "content": "hello world"
    },
    "success": true
  }],
  "parseErrors": []
}
```

### 002-multiple-blocks-mixed-success

```sh sham
#!SHAM [@three-char-SHA-256: f1r]
action = "file_write"
path = "/tmp/first.txt"
content = "first"
#!END_SHAM_f1r

Some text between blocks

#!SHAM [@three-char-SHA-256: s3c]
action = "file_write"
path = "/tmp/nonexistent/second.txt"
content = "fails"
#!END_SHAM_s3c
```

```json
{
  "success": false,
  "totalBlocks": 2,
  "executedActions": 2,
  "results": [{
    "seq": 1,
    "blockId": "f1r",
    "action": "file_write",
    "params": {
      "action": "file_write",
      "path": "/tmp/first.txt",
      "content": "first"
    },
    "success": true
  }, {
    "seq": 2,
    "blockId": "s3c",
    "action": "file_write",
    "params": {
      "action": "file_write",
      "path": "/tmp/nonexistent/second.txt",
      "content": "fails"
    },
    "success": false,
    "error": "ENOENT: no such file or directory"
  }],
  "parseErrors": []
}
```

## error handling

### 003-invalid-action

```sh sham
#!SHAM [@three-char-SHA-256: inv]
action = "invalid_action"
path = "/tmp/test.txt"
#!END_SHAM_inv
```

```json
{
  "success": false,
  "totalBlocks": 1,
  "executedActions": 0,
  "results": [{
    "seq": 1,
    "blockId": "inv",
    "action": "invalid_action",
    "params": {
      "action": "invalid_action",
      "path": "/tmp/test.txt"
    },
    "success": false,
    "error": "Unknown action: invalid_action"
  }],
  "parseErrors": []
}
```

### 004-parser-error-continues

```sh sham
#!SHAM [@three-char-SHA-256: dup]
key = "first"
key = "second"
#!END_SHAM_dup

#!SHAM [@three-char-SHA-256: ok]
action = "file_write"
path = "/tmp/after-error.txt"
content = "should work"
#!END_SHAM_ok
```

```json
{
  "success": false,
  "totalBlocks": 2,
  "executedActions": 1,
  "results": [{
    "seq": 1,
    "blockId": "ok",
    "action": "file_write",
    "params": {
      "action": "file_write",
      "path": "/tmp/after-error.txt",
      "content": "should work"
    },
    "success": true
  }],
  "parseErrors": [{
    "blockId": "dup",
    "error": {
      "code": "DUPLICATE_KEY",
      "message": "Duplicate key 'key' in block 'dup'"
    }
  }]
}
```

## command execution

### 005-exec-bash

```sh sham
#!SHAM [@three-char-SHA-256: cmd]
action = "exec"
code = "echo 'hello from shell'"
lang = "bash"
#!END_SHAM_cmd
```

```json
{
  "success": true,
  "totalBlocks": 1,
  "executedActions": 1,
  "results": [{
    "seq": 1,
    "blockId": "cmd",
    "action": "exec",
    "params": {
      "action": "exec",
      "code": "echo 'hello from shell'",
      "lang": "bash"
    },
    "success": true,
    "data": {
      "stdout": "hello from shell\n",
      "stderr": "",
      "exit_code": 0
    }
  }],
  "parseErrors": []
}
```
=== END FILE: ./proj/test-data/execute.md ===

=== START FILE: ./proj/comp/sham-action-parser/test/parseShamResponse.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { marked, Token } from 'marked';
import { parseShamResponse } from '../src/index';

const testPath = join(__dirname, '../test-data/parseShamResponse.md');
const mdContent = readFileSync(testPath, 'utf8');

const tokens: Token[] = marked.lexer(mdContent);
const codeBlocks = tokens.filter(t => t.type === 'code') as Array<Token & {type: 'code', text: string}>;
const testNames = tokens
  .filter(t => t.type === 'heading' && 'depth' in t && t.depth === 3)
  .map(t => (t as any).text as string);

describe('parseShamResponse', () => {
  testNames.forEach((name, i) => {
    const baseIndex = i * 2;
    it(name, async () => {
      const input = codeBlocks[baseIndex].text;
      const expected = JSON.parse(codeBlocks[baseIndex + 1].text);
      const result = await parseShamResponse(input);
      expect(result).toEqual(expected);
    });
  });
});
=== END FILE: ./proj/comp/sham-action-parser/test/parseShamResponse.test.ts ===

=== START FILE: ./proj/comp/sham-action-parser/test/validateShamBlock.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { validateShamBlock } from '../src/index';

const testData = JSON.parse(
  readFileSync(join(__dirname, '../test-data/validateShamBlock.json'), 'utf8')
);

describe('validateShamBlock', () => {
  testData.cases.forEach(({ name, input, expected }) => {
    it(name, () => {
      const [block, actionSchema] = input;
      const result = validateShamBlock(block, actionSchema);
      expect(result).toEqual(expected);
    });
  });
});
=== END FILE: ./proj/comp/sham-action-parser/test/validateShamBlock.test.ts ===

=== START FILE: ./proj/comp/sham-action-parser/test/transformToAction.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { transformToAction, TransformError } from '../src/index';

const testData = JSON.parse(
  readFileSync(join(__dirname, '../test-data/transformToAction.json'), 'utf8')
);

describe('transformToAction', () => {
  testData.cases.forEach(({ name, input, expected, throws }) => {
    it(name, () => {
      const [block, actionDef] = input;
      if (throws) {
        expect(() => transformToAction(block, actionDef)).toThrow(TransformError);
      } else {
        const result = transformToAction(block, actionDef);
        expect(result).toEqual(expected);
      }
    });
  });
});
=== END FILE: ./proj/comp/sham-action-parser/test/transformToAction.test.ts ===

=== START FILE: ./proj/comp/sham-action-parser/test-data/validateShamBlock.json ===
{
  "cases": [
    {
      "name": "valid file_write block",
      "input": [
        {
          "id": "abc",
          "properties": {
            "action": "file_write",
            "path": "/tmp/test.txt",
            "content": "hello"
          }
        },
        {
          "type": "write",
          "description": "Create new file",
          "parameters": {
            "path": {"type": "string", "required": true, "format": "absolute_path"},
            "content": {"type": "string", "required": true}
          }
        }
      ],
      "expected": {
        "valid": true,
        "actionType": "file_write",
        "errors": []
      }
    },
    {
      "name": "missing action field",
      "input": [
        {
          "id": "bad",
          "properties": {
            "path": "/tmp/test.txt",
            "content": "hello"
          }
        },
        null
      ],
      "expected": {
        "valid": false,
        "errors": ["Missing 'action' field in SHAM block"]
      }
    },
    {
      "name": "unknown action type",
      "input": [
        {
          "id": "unk",
          "properties": {
            "action": "not_real_action",
            "path": "/tmp/test.txt"
          }
        },
        null
      ],
      "expected": {
        "valid": false,
        "errors": ["Unknown action: not_real_action"]
      }
    },
    {
      "name": "missing required parameter",
      "input": [
        {
          "id": "miss",
          "properties": {
            "action": "file_write",
            "path": "/tmp/test.txt"
          }
        },
        {
          "type": "write",
          "description": "Create new file",
          "parameters": {
            "path": {"type": "string", "required": true, "format": "absolute_path"},
            "content": {"type": "string", "required": true}
          }
        }
      ],
      "expected": {
        "valid": false,
        "errors": ["Missing required parameter: content"]
      }
    }
  ]
}
=== END FILE: ./proj/comp/sham-action-parser/test-data/validateShamBlock.json ===

=== START FILE: ./proj/comp/sham-action-parser/test-data/transformToAction.json ===
{
  "cases": [
    {
      "name": "simple string parameters",
      "input": [
        {
          "id": "str",
          "properties": {
            "action": "file_write",
            "path": "/tmp/test.txt",
            "content": "hello world"
          },
          "startLine": 1,
          "endLine": 5
        },
        {
          "type": "write",
          "parameters": {
            "path": {"type": "string", "required": true, "format": "absolute_path"},
            "content": {"type": "string", "required": true}
          }
        }
      ],
      "expected": {
        "action": "file_write",
        "parameters": {
          "path": "/tmp/test.txt",
          "content": "hello world"
        },
        "metadata": {
          "blockId": "str",
          "startLine": 1,
          "endLine": 5
        }
      }
    },
    {
      "name": "with SHAM annotation",
      "input": [
        {
          "id": "ann",
          "properties": {
            "action": "file_delete",
            "path": "/tmp/remove.txt",
            "@three-char-SHA-256": "abc"
          },
          "startLine": 10,
          "endLine": 13
        },
        {
          "type": "write",
          "parameters": {
            "path": {"type": "string", "required": true, "format": "absolute_path"}
          }
        }
      ],
      "expected": {
        "action": "file_delete",
        "parameters": {
          "path": "/tmp/remove.txt"
        },
        "metadata": {
          "blockId": "ann",
          "startLine": 10,
          "endLine": 13
        }
      }
    },
    {
      "name": "integer parameter conversion",
      "input": [
        {
          "id": "int",
          "properties": {
            "action": "file_replace_text",
            "path": "/tmp/edit.txt",
            "old_text": "foo",
            "new_text": "bar",
            "count": "3"
          },
          "startLine": 1,
          "endLine": 7
        },
        {
          "type": "write",
          "parameters": {
            "path": {"type": "string", "required": true, "format": "absolute_path"},
            "old_text": {"type": "string", "required": true},
            "new_text": {"type": "string", "required": true},
            "count": {"type": "integer", "required": false, "default": 1}
          }
        }
      ],
      "expected": {
        "action": "file_replace_text",
        "parameters": {
          "path": "/tmp/edit.txt",
          "old_text": "foo",
          "new_text": "bar",
          "count": 3
        },
        "metadata": {
          "blockId": "int",
          "startLine": 1,
          "endLine": 7
        }
      }
    },
    {
      "name": "enum parameter validation",
      "input": [
        {
          "id": "enum",
          "properties": {
            "action": "exec",
            "code": "print(1)",
            "lang": "python"
          },
          "startLine": 5,
          "endLine": 9
        },
        {
          "type": "dynamic",
          "parameters": {
            "code": {"type": "string", "required": true},
            "lang": {"type": "enum", "values": ["python", "javascript", "bash", "ruby"], "required": true}
          }
        }
      ],
      "expected": {
        "action": "exec",
        "parameters": {
          "code": "print(1)",
          "lang": "python"
        },
        "metadata": {
          "blockId": "enum",
          "startLine": 5,
          "endLine": 9
        }
      }
    },
    {
      "name": "invalid integer throws",
      "input": [
        {
          "id": "bad",
          "properties": {
            "action": "file_replace_text",
            "path": "/tmp/edit.txt",
            "old_text": "foo",
            "new_text": "bar",
            "count": "not-a-number"
          },
          "startLine": 1,
          "endLine": 7
        },
        {
          "type": "write",
          "parameters": {
            "path": {"type": "string", "required": true},
            "old_text": {"type": "string", "required": true},
            "new_text": {"type": "string", "required": true},
            "count": {"type": "integer", "required": false}
          }
        }
      ],
      "throws": "TransformError"
    }
  ]
}
=== END FILE: ./proj/comp/sham-action-parser/test-data/transformToAction.json ===

=== START FILE: ./proj/comp/sham-action-parser/test-data/parseShamResponse.md ===
# Tests

## general

### 001-single-valid-file-create-action

```sh sham
#!SHAM [@three-char-SHA-256: abc]
action = "file_write"
path = "/tmp/test.txt"
content = <<'EOT_SHAM_abc'
Hello world!
EOT_SHAM_abc
#!END_SHAM_abc
````

```json
{
  "actions": [{
    "action": "file_write",
    "parameters": {
      "path": "/tmp/test.txt",
      "content": "Hello world!"
    },
    "metadata": {
      "blockId": "abc",
      "startLine": 1,
      "endLine": 7
    }
  }],
  "errors": [],
  "summary": {
    "totalBlocks": 1,
    "successCount": 1,
    "errorCount": 0
  }
}
```

---

### 002-multiple-blocks-with-one-invalid

```sh sham
#!SHAM [@three-char-SHA-256: gd1]
action = "file_write"
path = "/tmp/good.txt"
content = "valid"
#!END_SHAM_gd1

#!SHAM [@three-char-SHA-256: bad]
action = "unknown_action"
path = "/tmp/bad.txt"
#!END_SHAM_bad
```

```json
{
  "actions": [{
    "action": "file_write",
    "parameters": {
      "path": "/tmp/good.txt",
      "content": "valid"
    },
    "metadata": {
      "blockId": "gd1",
      "startLine": 1,
      "endLine": 5
    }
  }],
  "errors": [{
    "blockId": "bad",
    "action": "unknown_action",
    "errorType": "validation",
    "message": "Unknown action: unknown_action",
    "blockStartLine": 7,
    "shamContent": "#!SHAM [@three-char-SHA-256: bad]\naction = \"unknown_action\"\npath = \"/tmp/bad.txt\"\n#!END_SHAM_bad"
  }],
  "summary": {
    "totalBlocks": 2,
    "successCount": 1,
    "errorCount": 1
  }
}
```

---

### 003-missing-required-parameter

```sh sham
#!SHAM [@three-char-SHA-256: mis]
action = "file_write"
content = "missing path"
#!END_SHAM_mis
```

```json
{
  "actions": [],
  "errors": [{
    "blockId": "mis",
    "action": "file_write",
    "errorType": "validation",
    "message": "Missing required parameter: path",
    "blockStartLine": 1,
    "shamContent": "#!SHAM [@three-char-SHA-256: mis]\naction = \"file_write\"\ncontent = \"missing path\"\n#!END_SHAM_mis"
  }],
  "summary": {
    "totalBlocks": 1,
    "successCount": 0,
    "errorCount": 1
  }
}
```

---

### 004-type-conversion-with-boolean-and-integer

```sh sham
#!SHAM [@three-char-SHA-256: typ]
action = "exec"
code = "print('hi')"
lang = "python"
cwd = "/tmp"
#!END_SHAM_typ
```

```json
{
  "actions": [{
    "action": "exec",
    "parameters": {
      "code": "print('hi')",
      "lang": "python",
      "cwd": "/tmp"
    },
    "metadata": {
      "blockId": "typ",
      "startLine": 1,
      "endLine": 6
    }
  }],
  "errors": [],
  "summary": {
    "totalBlocks": 1,
    "successCount": 1,
    "errorCount": 0
  }
}
```

=== END FILE: ./proj/comp/sham-action-parser/test-data/parseShamResponse.md ===

=== START FILE: ./proj/comp/sham-action-parser/doc/API.md ===
# Component: sham-action-parser

## Component Type
standard

## Documentation Debt
[Must be empty before implementation]

## Dependencies
[Provisional - updated via STOP protocol when implementation reveals actual needs]

```yaml
dependencies:
  external/nesl-js:
    functions: [parseSham]
    types: [Block, ParseResult, ParseError]
  
  external/js-yaml:
    functions: [load]
    types: []
  
  node:fs/promises:
    functions: [readFile]
    types: []
  
  node:path:
    functions: [resolve, join]
    types: []
```

## Exports
```yaml
exports:
  functions: [parseShamResponse, validateShamBlock, transformToAction]
  types: [ParseResult, CladaAction, ParseError, ValidationResult, TransformError]
  errors: [TransformError]
```

### parseShamResponse
- **Signature**: `parseShamResponse(shamText: string) -> Promise<ParseResult>`
- **Purpose**: Parse SHAM blocks from text into validated clada actions.
- **Test-data**: `test-data/parseShamResponse.json`

### validateShamBlock
- **Signature**: `validateShamBlock(block: ShamBlock, actionSchema: ActionDefinition) -> ValidationResult`
- **Purpose**: Validate a single SHAM block against action schema.
- **Test-data**: `test-data/validateShamBlock.json`

### transformToAction
- **Signature**: `transformToAction(block: ShamBlock, actionDef: ActionDefinition) -> CladaAction`
- **Purpose**: Transform validated SHAM block into typed clada action.
- **Throws**: `TransformError` when type conversion fails
- **Test-data**: `test-data/transformToAction.json`

## Internal Functions
[Discovered during implementation - not exported]

### loadActionSchema
- **Signature**: `loadActionSchema() -> Promise<Map<string, ActionDefinition>>`
- **Purpose**: Load and parse unified-design.yaml action definitions.

### parseBoolean
- **Signature**: `parseBoolean(value: string) -> boolean`
- **Purpose**: Convert string "true"/"false" to boolean.

### parseInteger  
- **Signature**: `parseInteger(value: string) -> number`
- **Purpose**: Convert numeric string to integer.
- **Throws**: `TransformError` when not a valid integer

### validateAbsolutePath
- **Signature**: `validateAbsolutePath(path: string) -> boolean`
- **Purpose**: Check if string is valid absolute path.

### validateEnum
- **Signature**: `validateEnum(value: string, allowed: string[]) -> boolean`
- **Purpose**: Check if value is in allowed enum values.

## Types

### ParseResult
```typescript
{
  actions: CladaAction[]      // Successfully parsed actions
  errors: ParseError[]        // All errors encountered
  summary: {
    totalBlocks: number
    successCount: number
    errorCount: number
  }
}
```

### CladaAction
```typescript
{
  action: string              // Action name from unified-design
  parameters: Record<string, any>  // Typed parameters
  metadata: {
    blockId: string          // SHAM block ID
    startLine: number
    endLine: number
  }
}
```

### ParseError
```typescript
{
  blockId: string            // Which SHAM block failed
  errorType: 'syntax' | 'validation' | 'type'
  message: string            // Specific error details
  blockStartLine?: number    // Starting line of the SHAM block
  shamContent?: string       // Original SHAM block for context
}
```

### ValidationResult
```typescript
{
  valid: boolean
  actionType?: string        // Identified action if valid
  errors?: string[]          // Validation errors if invalid
}
```

### TransformError
```typescript
class TransformError extends Error {
  parameterName: string
  expectedType: string
  actualValue: string
}
```

### ActionDefinition
```typescript
{
  type: 'read' | 'write' | 'meta' | 'git' | 'dynamic'
  description: string
  parameters: Record<string, ParameterDef>
  returns: Record<string, any>
}
```

### ParameterDef
```typescript
{
  type: string              // 'string' | 'integer' | 'boolean' | 'enum'
  required: boolean
  format?: string           // e.g. 'absolute_path'
  values?: string[]         // for enum type
  default?: any
}
```
=== END FILE: ./proj/comp/sham-action-parser/doc/API.md ===

=== START FILE: ./proj/comp/sham-action-parser/doc/ABSTRACT.md ===
# SHAM Action Parser

Parses SHAM blocks from LLM responses into validated clada action objects, executing as many valid actions as possible while collecting errors for failed blocks.

## Overview

This component bridges between LLM-generated SHAM syntax and clada's action system. It processes text containing SHAM blocks, validates each block independently against clada's action schema, and transforms valid blocks into executable action objects. The parser is intentionally permissive - it processes all blocks and collects both successes and failures, allowing clada to execute valid actions while reporting specific errors back to the LLM for correction. This design minimizes expensive LLM regeneration by salvaging partial success from responses containing some malformed blocks.

The parser handles:
- SHAM syntax parsing via nesl-js
- Action type validation against unified-design schema  
- Parameter presence and type checking
- String-to-type conversions (booleans, integers, paths)
- Comprehensive error collection with block context
- Preservation of SHAM metadata (IDs, line numbers)

This approach enables efficient LLM-clada interaction by providing detailed feedback on exactly which actions failed and why, allowing targeted corrections rather than full regeneration.
=== END FILE: ./proj/comp/sham-action-parser/doc/ABSTRACT.md ===

=== START FILE: ./proj/comp/sham-action-parser/doc/ARCH.md ===
# SHAM Action Parser - Architecture

## Design Philosophy

**Maximize Execution, Minimize Regeneration**: Parse and validate each SHAM block independently. Execute all valid actions while collecting detailed errors for invalid ones. This avoids expensive LLM token usage for full response regeneration.

## Processing Pipeline

1. **SHAM Parsing** (via nesl-js)
   - Input: Raw text with SHAM blocks
   - Output: Parsed blocks with string properties
   - Preserves: Block IDs, line numbers, raw content

2. **Action Validation** (per block)
   - Validate `action` field exists and matches known clada actions
   - Check required parameters for specific action type
   - Continue processing even if some blocks fail

3. **Type Transformation** (per valid block)
   - Convert string values to appropriate types
   - Validate constraints (path formats, enum values, etc.)
   - Preserve original SHAM metadata

4. **Result Aggregation**
   - Collect all successful action objects
   - Collect all errors with context
   - Return comprehensive ParseResult

## Error Handling Strategy

Each block processed independently with errors collected in structured format:
- `blockId`: SHAM block identifier
- `blockStartLine`: Starting line number of the SHAM block in original text
- `errorType`: Category (syntax, validation, type)
- `message`: Specific error details
- `shamContent`: Original SHAM block for LLM reference

## Type Conversions

All SHAM values are strings, requiring conversion:
- **Booleans**: "true"/"false" → boolean
- **Integers**: Numeric strings → number
- **Paths**: Validate absolute path format
- **Enums**: Validate against allowed values
- **Arrays**: Not supported in SHAM (would need special syntax)

## Action Mapping

SHAM actions map directly to clada tool names from unified-design.yaml:
- Must use exact tool names (e.g., `file_write`, not `write_file`)
- No aliasing or fuzzy matching to avoid ambiguity

## Constraints

- SHAM doesn't support complex types (objects, arrays)
- All values are strings requiring parsing
- No nested structures
- Heredoc strings preserve internal formatting

## Dependencies on Other Components

- Requires action schema definitions (types, required params)
- Will need shared error types with response formatter
- Path validation utilities
=== END FILE: ./proj/comp/sham-action-parser/doc/ARCH.md ===

=== START FILE: ./proj/comp/sham-action-parser/src/transformToAction.ts ===
import { CladaAction, TransformError, ActionDefinition } from './types.js';
import type { Block } from 'nesl-js';

/**
 * Transform validated SHAM block into typed clada action
 * Converts string values to proper types based on schema
 */
export function transformToAction(
  block: Block,
  actionDef: ActionDefinition
): CladaAction {
  const action = block.properties.action;
  if (!action) {
    throw new TransformError(
      'Block missing action property',
      'action',
      'string',
      'undefined'
    );
  }
  const parameters: Record<string, any> = {};

  // Process each parameter defined in the schema
  for (const [paramName, paramDef] of Object.entries(actionDef.parameters || {})) {
    // Skip if parameter not provided and has a default
    if (!(paramName in block.properties)) {
      if ('default' in paramDef) {
        parameters[paramName] = paramDef.default;
      }
      continue;
    }

    const rawValue = block.properties[paramName];
    
    // Skip if value is undefined (shouldn't happen if we got here, but TypeScript needs this)
    if (rawValue === undefined) {
      continue;
    }

    try {
      // Convert based on parameter type
      switch (paramDef.type) {
        case 'string':
          parameters[paramName] = rawValue;
          // Validate format if specified
          if (paramDef.format === 'absolute_path' && !validateAbsolutePath(rawValue)) {
            throw new TransformError(
              `Invalid absolute path: ${rawValue}`,
              paramName,
              'absolute_path',
              rawValue
            );
          }
          break;

        case 'integer':
          parameters[paramName] = parseInteger(rawValue);
          break;

        case 'boolean':
          parameters[paramName] = parseBoolean(rawValue);
          break;

        case 'enum':
          if (!paramDef.values || !paramDef.values.includes(rawValue)) {
            throw new TransformError(
              `Invalid enum value: ${rawValue}. Allowed: ${paramDef.values?.join(', ')}`,
              paramName,
              'enum',
              rawValue
            );
          }
          parameters[paramName] = rawValue;
          break;

        default:
          // Default to string for unknown types
          parameters[paramName] = rawValue;
      }
    } catch (error) {
      if (error instanceof TransformError) {
        // Update parameter name in error
        error.parameterName = paramName;
        throw error;
      }
      throw new TransformError(
        `Failed to transform parameter ${paramName}: ${error}`,
        paramName,
        paramDef.type,
        rawValue
      );
    }
  }

  return {
    action,
    parameters,
    metadata: {
      blockId: block.id,
      startLine: block.startLine,
      endLine: block.endLine ?? block.startLine // Use startLine if endLine is null
    }
  };
}

// Helper functions for type conversion and validation

function parseBoolean(value: string): boolean {
  if (value === 'true') return true;
  if (value === 'false') return false;
  throw new TransformError(
    `Invalid boolean value: ${value}`,
    'unknown',
    'boolean',
    value
  );
}

function parseInteger(value: string): number {
  const num = parseInt(value, 10);
  if (isNaN(num) || num.toString() !== value.trim()) {
    throw new TransformError(
      `Invalid integer value: ${value}`,
      'unknown',
      'integer',
      value
    );
  }
  return num;
}

function validateAbsolutePath(path: string): boolean {
  // Unix/Linux/Mac absolute paths start with /
  // Windows absolute paths like C:\ or \\server\share
  return /^(\/|[A-Za-z]:\\|\\\\)/.test(path);
}
=== END FILE: ./proj/comp/sham-action-parser/src/transformToAction.ts ===

=== START FILE: ./proj/comp/sham-action-parser/src/types.ts ===
export interface ParseResult {
  actions: CladaAction[];
  errors: ParseError[];
  summary: {
    totalBlocks: number;
    successCount: number;
    errorCount: number;
  };
}

export interface CladaAction {
  action: string;
  parameters: Record<string, any>;
  metadata: {
    blockId: string;
    startLine: number;
    endLine: number;
  };
}

export interface ParseError {
  blockId: string;
  action?: string;
  errorType: 'syntax' | 'validation' | 'type';
  message: string;
  blockStartLine?: number;
  shamContent?: string;
}

export interface ValidationResult {
  valid: boolean;
  actionType?: string;
  errors?: string[];
}

export class TransformError extends Error {
  constructor(
    message: string,
    public parameterName: string,
    public expectedType: string,
    public actualValue: string
  ) {
    super(message);
    this.name = 'TransformError';
  }
}

export interface ActionDefinition {
  type: 'read' | 'write' | 'meta' | 'git' | 'dynamic';
  description: string;
  parameters: Record<string, ParameterDef>;
  returns?: Record<string, any>;
}

export interface ParameterDef {
  type: string;
  required: boolean;
  format?: string;
  values?: string[];
  default?: any;
}
=== END FILE: ./proj/comp/sham-action-parser/src/types.ts ===

=== START FILE: ./proj/comp/sham-action-parser/src/validateShamBlock.ts ===
import { ValidationResult, ActionDefinition } from './types.js';
import type { Block } from 'nesl-js';

/**
 * Validate a single SHAM block against action schema
 * Checks action exists and required params present
 */
export function validateShamBlock(
  block: Block,
  actionSchema: ActionDefinition | null
): ValidationResult {
  // Check if block has properties object
  if (!block.properties) {
    return {
      valid: false,
      errors: ['Block missing properties object']
    };
  }

  // Check if action field exists
  if (!block.properties.action) {
    return {
      valid: false,
      errors: ['Missing \'action\' field in SHAM block']
    };
  }

  const actionType = block.properties.action;

  // If no schema provided, it's an unknown action
  if (!actionSchema) {
    return {
      valid: false,
      errors: [`Unknown action: ${actionType}`]
    };
  }

  // Check all required parameters are present
  const errors: string[] = [];
  
  if (actionSchema.parameters) {
    for (const [paramName, paramDef] of Object.entries(actionSchema.parameters)) {
      if (paramDef.required && !(paramName in block.properties)) {
        errors.push(`Missing required parameter: ${paramName}`);
      }
    }
  }

  if (errors.length > 0) {
    return {
      valid: false,
      errors
    };
  }

  return {
    valid: true,
    actionType,
    errors: []
  };
}
=== END FILE: ./proj/comp/sham-action-parser/src/validateShamBlock.ts ===

=== START FILE: ./proj/comp/sham-action-parser/src/index.ts ===
/**
 * SHAM Action Parser - Parses SHAM blocks into validated clada actions
 */

import { ParseResult, CladaAction, ParseError, ValidationResult, TransformError, ActionDefinition } from './types.js';
import { validateShamBlock } from './validateShamBlock.js';
import { transformToAction } from './transformToAction.js';
import { parseSham, type Block, type ParseResult as NeslParseResult } from 'nesl-js';
import { load as loadYaml } from 'js-yaml';
import { readFile } from 'fs/promises';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

// Re-export types for consumers
export { ParseResult, CladaAction, ParseError, ValidationResult, TransformError };

// Cache for action schema
let actionSchemaCache: Map<string, ActionDefinition> | null = null;

/**
 * Parse SHAM blocks from text into validated clada actions
 * Processes all blocks, collecting successes and errors
 */
export async function parseShamResponse(shamText: string): Promise<ParseResult> {
  const actions: CladaAction[] = [];
  const errors: ParseError[] = [];

  // Parse SHAM blocks using nesl-js
  let parseResult: NeslParseResult;
  try {
    parseResult = parseSham(shamText);
    
    // Handle case where parseSham returns undefined or null
    if (!parseResult) {
      parseResult = { blocks: [], errors: [] };
    }
  } catch (error) {
    return {
      actions: [],
      errors: [{
        blockId: 'unknown',
        errorType: 'syntax',
        message: `Failed to parse SHAM: ${error}`,
        shamContent: shamText
      }],
      summary: {
        totalBlocks: 0,
        successCount: 0,
        errorCount: 1
      }
    };
  }

  // Load action schema
  const actionSchema = await loadActionSchema();

  // Process each SHAM block
  const blocks = parseResult.blocks || [];
  
  // If no blocks found, return empty result
  if (blocks.length === 0) {
    return {
      actions: [],
      errors: [],
      summary: {
        totalBlocks: 0,
        successCount: 0,
        errorCount: 0
      }
    };
  }
  
  for (const block of blocks) {
    const blockId = block.id || 'unknown';
    
    try {
      // Get action type from block
      const actionType = block.properties?.action;
      const actionDef = actionType ? actionSchema.get(actionType) : undefined;

      // Validate block
      const validation = validateShamBlock(block, actionDef ?? null);
      
      if (!validation.valid) {
        errors.push({
          blockId,
          action: actionType,
          errorType: 'validation',
          message: validation.errors?.[0] || 'Validation failed',
          blockStartLine: block.startLine,
          shamContent: reconstructShamBlock(block)
        });
        continue;
      }

      // Transform to action
      try {
        const action = transformToAction(block, actionDef!);
        actions.push(action);
      } catch (error) {
        if (error instanceof TransformError) {
          errors.push({
            blockId,
            action: actionType,
            errorType: 'type',
            message: error.message,
            blockStartLine: block.startLine,
            shamContent: reconstructShamBlock(block)
          });
        } else {
          throw error;
        }
      }
    } catch (error) {
      errors.push({
        blockId,
        action: block.properties?.action,
        errorType: 'validation',
        message: `Unexpected error: ${error}`,
        blockStartLine: block.startLine,
        shamContent: reconstructShamBlock(block)
      });
    }
  }

  return {
    actions,
    errors,
    summary: {
      totalBlocks: blocks.length,
      successCount: actions.length,
      errorCount: errors.length
    }
  };
}

/**
 * Load and cache action definitions from unified-design.yaml
 */
async function loadActionSchema(): Promise<Map<string, ActionDefinition>> {
  if (actionSchemaCache) {
    return actionSchemaCache;
  }

  // Get the directory of this module
  const __filename = fileURLToPath(import.meta.url);
  const __dirname = dirname(__filename);
  
  // Navigate to project root and find unified-design.yaml
  const yamlPath = join(__dirname, '../../../../unified-design.yaml');
  
  try {
    const yamlContent = await readFile(yamlPath, 'utf8');
    const design = loadYaml(yamlContent) as any;
    
    actionSchemaCache = new Map();
    
    // Extract tool definitions
    if (design.tools) {
      for (const [toolName, toolDef] of Object.entries(design.tools)) {
        actionSchemaCache.set(toolName, toolDef as ActionDefinition);
      }
    }
    
    return actionSchemaCache;
  } catch (error) {
    throw new Error(`Failed to load unified-design.yaml: ${error}`);
  }
}

/**
 * Reconstruct SHAM block text for error context
 */
function reconstructShamBlock(block: Block): string {
  const lines: string[] = [];
  
  // Start line
  lines.push(`#!SHAM [@three-char-SHA-256: ${block.id || 'unknown'}]`);
  
  // Properties
  for (const [key, value] of Object.entries(block.properties || {})) {
    if (key.startsWith('@')) continue; // Skip annotations
    
    if (typeof value === 'string' && value.includes('\n')) {
      // Multi-line value with heredoc
      lines.push(`${key} = <<'EOT_SHAM_${block.id}'`);
      lines.push(value);
      lines.push(`EOT_SHAM_${block.id}`);
    } else {
      // Single line value - use JSON.stringify to handle quotes properly
      lines.push(`${key} = ${JSON.stringify(value)}`);
    }
  }
  
  // End line
  lines.push(`#!END_SHAM_${block.id || 'unknown'}`);
  
  return lines.join('\n');
}

// Re-export functions for consumers
export { validateShamBlock, transformToAction };
=== END FILE: ./proj/comp/sham-action-parser/src/index.ts ===

=== START FILE: ./proj/comp/fs-ops/test/unit/formatNodeError.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { formatNodeError } from '../../src/formatNodeError.js';

const testData = JSON.parse(
  readFileSync(join(__dirname, '../../test-data/unit/formatNodeError.cases.json'), 'utf8')
);

describe('formatNodeError', () => {
  testData.cases.forEach(({ name, input, expected }) => {
    it(name, () => {
      const result = formatNodeError(...input);
      expect(result).toEqual(expected);
    });
  });
});
=== END FILE: ./proj/comp/fs-ops/test/unit/formatNodeError.test.ts ===

=== START FILE: ./proj/comp/fs-ops/test/unit/getParentDirectory.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { getParentDirectory } from '../../src/getParentDirectory.js';

const testData = JSON.parse(
  readFileSync(join(__dirname, '../../test-data/unit/getParentDirectory.cases.json'), 'utf8')
);

describe('getParentDirectory', () => {
  testData.cases.forEach(({ name, input, expected }) => {
    it(name, () => {
      const result = getParentDirectory(...input);
      expect(result).toEqual(expected);
    });
  });
});
=== END FILE: ./proj/comp/fs-ops/test/unit/getParentDirectory.test.ts ===

=== START FILE: ./proj/comp/fs-ops/test/unit/getByteLength.test.ts ===
import { describe, it, expect } from 'vitest';
import { readFileSync } from 'fs';
import { join } from 'path';
import { getByteLength } from '../../src/getByteLength.js';

const testData = JSON.parse(
  readFileSync(join(__dirname, '../../test-data/unit/getByteLength.cases.json'), 'utf8')
);

describe('getByteLength', () => {
  testData.cases.forEach(({ name, input, expected }) => {
    it(name, () => {
      const result = getByteLength(...input);
      expect(result).toEqual(expected);
    });
  });
});
=== END FILE: ./proj/comp/fs-ops/test/unit/getByteLength.test.ts ===

=== START FILE: ./proj/comp/fs-ops/test/unit/replaceText.test.ts ===
import { describe, it, expect } from 'vitest';
import { replaceText } from '../../src/replaceText';
import { cases } from '../../test-data/unit/replaceText.cases';

describe('replaceText', () => {
  cases.forEach(({ name, input, expected }) => {
    it(name, () => {
      const result = replaceText(...input);
      expect(result).toEqual(expected);
    });
  });
});

=== END FILE: ./proj/comp/fs-ops/test/unit/replaceText.test.ts ===

=== START FILE: ./proj/comp/fs-ops/test/integration/integration.test.ts ===
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { readFileSync, rmSync, existsSync } from 'fs';
import { join } from 'path';
import { marked, Token } from 'marked';
import { parseShamResponse } from '../../../sham-action-parser/src/index.js';
import { executeFileOperation } from '../../src/index.js';

// Read test data
const testPath = join(__dirname, '../../test-data/integration/file-operations.cases.md');
const mdContent = readFileSync(testPath, 'utf8');

// Parse markdown to extract test cases
const tokens: Token[] = marked.lexer(mdContent);
const codeBlocks = tokens.filter(t => t.type === 'code') as Array<Token & {type: 'code', text: string}>;
const testNames = tokens
  .filter(t => t.type === 'heading' && 'depth' in t && t.depth === 3)
  .map(t => (t as any).text as string);

// Test cleanup paths
const testPaths = [
  '/tmp/test.txt',
  '/tmp/deeply',
  '/tmp/existing.txt',
  '/tmp/multiline.txt'
];

describe('fs-ops integration tests', () => {
  beforeEach(() => {
    // Clean up any existing test files
    testPaths.forEach(path => {
      if (existsSync(path)) {
        rmSync(path, { recursive: true, force: true });
      }
    });
  });

  afterEach(() => {
    // Clean up after tests
    testPaths.forEach(path => {
      if (existsSync(path)) {
        rmSync(path, { recursive: true, force: true });
      }
    });
  });

  testNames.forEach((name, i) => {
    const baseIndex = i * 2;
    it(name, async () => {
      const shamInput = codeBlocks[baseIndex].text;
      const expectedOutput = JSON.parse(codeBlocks[baseIndex + 1].text);
      
      // Set up test preconditions
      if (name === '003-file-already-exists') {
        // Create the file that should already exist
        const { writeFileSync } = await import('fs');
        writeFileSync('/tmp/existing.txt', 'This file already exists');
      }
      
      // Parse SHAM to get actions
      const parseResult = await parseShamResponse(shamInput);
      
      // Should have exactly one action
      expect(parseResult.actions).toHaveLength(1);
      expect(parseResult.errors).toHaveLength(0);
      
      // Execute the action
      const result = await executeFileOperation(parseResult.actions[0]);
      
      // Compare result
      expect(result).toEqual(expectedOutput);
    });
  });
});
=== END FILE: ./proj/comp/fs-ops/test/integration/integration.test.ts ===

=== START FILE: ./proj/comp/fs-ops/test-data/unit/replaceText.cases.ts ===
export const cases = [
  {
    name: "simple replacement",
    input: ["hello world", "world", "universe"],
    expected: {
      result: "hello universe",
      replacements: 1,
    },
  },
  {
    name: "multiple replacements",
    input: ["foo bar foo baz", "foo", "qux"],
    expected: {
      result: "qux bar qux baz",
      replacements: 2,
    },
  },
  {
    name: "limited replacements",
    input: ["foo bar foo baz foo", "foo", "qux", 2],
    expected: {
      result: "qux bar qux baz foo",
      replacements: 2,
    },
  },
  {
    name: "multiline content replacement",
    input: [
`function oldName() {
  console.log('oldName');
  return oldName;
}`,
      "oldName",
      "newName",
    ],
    expected: {
      result: 
`function newName() {
  console.log('newName');
  return newName;
}`,
      replacements: 3,
    },
  },
  {
    name: "multiline search and replace",
    input: [
`const config = {
  old: {
    setting: true
  },
  other: false
};`,
`old: {
    setting: true
  }`,
`new: {
    setting: false,
    extra: 'value'
  }`,
    ],
    expected: {
      result: 
`const config = {
  new: {
    setting: false,
    extra: 'value'
  },
  other: false
};`,
      replacements: 1,
    },
  },
  {
    name: "replace code block with limit",
    input: [
`// TODO: fix this
function broken() {
  // TODO: fix this
  return null;
}
// TODO: fix this`,
      "// TODO: fix this",
      "// FIXED",
      2,
    ],
    expected: {
      result: 
`// FIXED
function broken() {
  // FIXED
  return null;
}
// TODO: fix this`,
      replacements: 2,
    },
  },
  {
    name: "no matches in multiline",
    input: [
`Line 1
Line 2
Line 3`,
      "Line 4",
      "Line X",
    ],
    expected: {
      result: 
`Line 1
Line 2
Line 3`,
      replacements: 0,
    },
  },
  {
    name: "empty old text",
    input: ["hello world", "", "xyz"],
    expected: {
      result: "hello world",
      replacements: 0,
    },
  },
  {
    name: "overlapping replacements",
    input: ["aaaa", "aa", "b"],
    expected: {
      result: "bb",
      replacements: 2,
    },
  },
  {
    name: "replace with empty string",
    input: ["foo bar foo", "foo ", ""],
    expected: {
      result: "bar foo",
      replacements: 1,
    },
  },
  {
    name: "windows line endings",
    input: ["line1\r\nline2\r\nline3", "\r\n", "\n"],
    expected: {
      result: "line1\nline2\nline3",
      replacements: 2,
    },
  },
  {
    name: "indent-sensitive replacement",
    input: [
`class OldClass:
    def method(self):
        pass`,
      "OldClass",
      "NewClass",
    ],
    expected: {
      result: 
`class NewClass:
    def method(self):
        pass`,
      replacements: 1,
    },
  },
];

=== END FILE: ./proj/comp/fs-ops/test-data/unit/replaceText.cases.ts ===

=== START FILE: ./proj/comp/fs-ops/test-data/unit/getParentDirectory.cases.json ===
{
  "cases": [
    {
      "name": "simple file path",
      "input": ["/tmp/test.txt"],
      "expected": "/tmp"
    },
    {
      "name": "nested file path",
      "input": ["/tmp/deeply/nested/file.txt"],
      "expected": "/tmp/deeply/nested"
    },
    {
      "name": "root level file",
      "input": ["/test.txt"],
      "expected": "/"
    },
    {
      "name": "directory path with trailing slash",
      "input": ["/tmp/dir/"],
      "expected": "/tmp"
    },
    {
      "name": "directory path without trailing slash",
      "input": ["/tmp/dir"],
      "expected": "/tmp"
    },
    {
      "name": "windows style path",
      "input": ["C:\\Users\\test\\file.txt"],
      "expected": "C:\\Users\\test"
    }
  ]
}
=== END FILE: ./proj/comp/fs-ops/test-data/unit/getParentDirectory.cases.json ===

=== START FILE: ./proj/comp/fs-ops/test-data/unit/getByteLength.cases.json ===
{
  "cases": [
    {
      "name": "simple ASCII string",
      "input": ["Hello, World!"],
      "expected": 13
    },
    {
      "name": "empty string",
      "input": [""],
      "expected": 0
    },
    {
      "name": "string with newlines",
      "input": ["Line 1\nLine 2\nLine 3"],
      "expected": 20
    },
    {
      "name": "unicode emoji",
      "input": ["Hello 👋 World"],
      "expected": 16
    },
    {
      "name": "multi-byte characters",
      "input": ["你好世界"],
      "expected": 12
    },
    {
      "name": "mixed ASCII and unicode",
      "input": ["Test: 测试"],
      "expected": 12
    }
  ]
}
=== END FILE: ./proj/comp/fs-ops/test-data/unit/getByteLength.cases.json ===

=== START FILE: ./proj/comp/fs-ops/test-data/unit/formatNodeError.cases.json ===
{
  "cases": [
    {
      "name": "ENOENT error",
      "input": [
        { "code": "ENOENT", "message": "no such file or directory" },
        "/tmp/missing.txt",
        "open"
      ],
      "expected": "ENOENT: no such file or directory, open '/tmp/missing.txt'"
    },
    {
      "name": "EEXIST error",
      "input": [
        { "code": "EEXIST", "message": "file already exists" },
        "/tmp/existing.txt",
        "open"
      ],
      "expected": "EEXIST: file already exists, open '/tmp/existing.txt'"
    },
    {
      "name": "EACCES error",
      "input": [
        { "code": "EACCES", "message": "permission denied" },
        "/root/forbidden.txt",
        "open"
      ],
      "expected": "EACCES: permission denied, open '/root/forbidden.txt'"
    },
    {
      "name": "EISDIR error",
      "input": [
        { "code": "EISDIR", "message": "illegal operation on a directory" },
        "/tmp/",
        "read"
      ],
      "expected": "EISDIR: illegal operation on a directory, read '/tmp/'"
    },
    {
      "name": "unknown error code",
      "input": [
        { "code": "ESOMETHING", "message": "something went wrong" },
        "/tmp/file.txt",
        "write"
      ],
      "expected": "ESOMETHING: something went wrong"
    },
    {
      "name": "error without code",
      "input": [
        { "message": "Generic error occurred" },
        "/tmp/file.txt",
        "write"
      ],
      "expected": "Generic error occurred"
    },
    {
      "name": "error with no message or code",
      "input": [
        {},
        "/tmp/file.txt",
        "write"
      ],
      "expected": "Unknown error during write on '/tmp/file.txt'"
    }
  ]
}
=== END FILE: ./proj/comp/fs-ops/test-data/unit/formatNodeError.cases.json ===

=== START FILE: ./proj/comp/fs-ops/test-data/integration/file-operations.cases.md ===
# File Operations Integration Tests

**Status**: [PLANNED] - Preliminary test format, subject to change

## file_write

### 001-simple-file-create

```sh sham
#!SHAM [@three-char-SHA-256: abc]
action = "file_write"
path = "/tmp/test.txt"
content = "Hello, World!"
#!END_SHAM_abc
```

```json
{
  "success": true,
  "data": {
    "path": "/tmp/test.txt",
    "bytesWritten": 13
  }
}
```

### 002-create-with-parent-dirs

```sh sham
#!SHAM [@three-char-SHA-256: pdr]
action = "file_write"
path = "/tmp/deeply/nested/dir/file.txt"
content = "Creates parent directories"
#!END_SHAM_pdr
```

```json
{
  "success": true,
  "data": {
    "path": "/tmp/deeply/nested/dir/file.txt",
    "bytesWritten": 26,
    "createdDirs": [
      "/tmp/deeply",
      "/tmp/deeply/nested", 
      "/tmp/deeply/nested/dir"
    ]
  }
}
```


### 004-permission-denied

```sh sham
#!SHAM [@three-char-SHA-256: prm]
action = "file_write"
path = "/root/forbidden.txt"
content = "Cannot write here"
#!END_SHAM_prm
```

```json
{
  "success": false,
  "error": "EROFS: EROFS: read-only file system, mkdir '/root'"
}
```

### 005-multiline-content

```sh sham
#!SHAM [@three-char-SHA-256: mlt]
action = "file_write"
path = "/tmp/multiline.txt"
content = <<'EOT_SHAM_mlt'
Line 1
Line 2
Line 3
EOT_SHAM_mlt
#!END_SHAM_mlt
```

```json
{
  "success": true,
  "data": {
    "path": "/tmp/multiline.txt",
    "bytesWritten": 20
  }
}
```
=== END FILE: ./proj/comp/fs-ops/test-data/integration/file-operations.cases.md ===

=== START FILE: ./proj/comp/fs-ops/doc/API.md ===
# Component: fs-ops

## Component Type
standard

## Documentation Debt
- [ ] Integration test format is preliminary [IMPLEMENTED]
- [ ] Error handling strategy needs refinement
- [ ] Consider batching operations for efficiency

## Dependencies

```yaml
dependencies:
  node:fs/promises:
    functions: [writeFile, readFile, unlink, mkdir, rmdir, readdir, stat]
    
  node:path:
    functions: [dirname, resolve, join]
    
  node:util:
    functions: [promisify]
    
  node:child_process:
    functions: [exec]  # for grep functionality
```

## Exports

```yaml
exports:
  functions: [executeFileOperation]
  types: [FileOpResult, FileOpError]
```

### executeFileOperation
- **Signature**: `executeFileOperation(action: CladaAction) -> Promise<FileOpResult>`
- **Purpose**: Execute file system operations from parsed SHAM actions
- **Throws**: Never - all errors captured in FileOpResult
- **Test-data**: `test-data/integration/file-operations.md` [PLANNED]

### FileOpResult (type)
```typescript
interface FileOpResult {
  success: boolean
  data?: any           // Operation-specific return data
  error?: string       // Error message if failed
}
```

### FileOpError (type)
```typescript
interface FileOpError extends Error {
  code: string         // e.g., 'ENOENT', 'EACCES'
  path?: string        // File path involved
  operation: string    // Which operation failed
}
```

## Internal Functions

### createFile
- **Signature**: `createFile(path: string, content: string) -> Promise<void>`
- **Purpose**: Create new file with content, creating parent directories as needed

### writeFile  
- **Signature**: `writeFile(path: string, content: string) -> Promise<void>`
- **Purpose**: Overwrite existing file content

### editFile
- **Signature**: `editFile(path: string, oldText: string, newText: string, count?: number) -> Promise<number>`
- **Purpose**: Replace text occurrences in file, returns replacement count

### deleteFile
- **Signature**: `deleteFile(path: string) -> Promise<void>`
- **Purpose**: Remove file

### moveFile
- **Signature**: `moveFile(oldPath: string, newPath: string) -> Promise<void>`
- **Purpose**: Move or rename file

### readFileContent
- **Signature**: `readFileContent(path: string) -> Promise<string>`
- **Purpose**: Read file content as UTF-8 string

### createDirectory
- **Signature**: `createDirectory(path: string) -> Promise<void>`
- **Purpose**: Create directory, including parent directories

### deleteDirectory
- **Signature**: `deleteDirectory(path: string) -> Promise<void>`
- **Purpose**: Remove directory (must be empty)

### listDirectory
- **Signature**: `listDirectory(path: string) -> Promise<DirEntry[]>`
- **Purpose**: List directory contents with metadata

### searchFiles
- **Signature**: `searchFiles(pattern: string, path: string, include?: string) -> Promise<GrepResult[]>`
- **Purpose**: Search for pattern in files (grep-like)

### globFiles
- **Signature**: `globFiles(pattern: string, basePath: string) -> Promise<string[]>`
- **Purpose**: Find files matching glob pattern

## Action Mapping

```typescript
const actionHandlers = {
  'file_write': writeFile,
  'file_replace_text': editFile,
  'file_delete': deleteFile,
  'file_move': moveFile,
  'file_read': readFileContent,
  'dir_create': createDirectory,
  'dir_delete': deleteDirectory,
  'ls': listDirectory,
  'grep': searchFiles,
  'glob': globFiles
}
```
=== END FILE: ./proj/comp/fs-ops/doc/API.md ===

=== START FILE: ./proj/comp/fs-ops/doc/DESIGN_TEMP.md ===
# fs-ops Design & Implementation Notes

**Status**: TEMPORARY - Implementation planning document

## Pseudocode for executeFileOperation

```javascript
async function executeFileOperation(action: CladaAction): Promise<FileOpResult> {
  try {
    // Get handler for action type
    const handler = actionHandlers[action.action];
    
    if (!handler) {
      return {
        success: false,
        error: `Unknown action: ${action.action}`
      };
    }
    
    // Call handler with action
    return await handler(action);
    
  } catch (error) {
    // This should never happen - handlers should catch their own errors
    return {
      success: false,
      error: `Unexpected error in executeFileOperation: ${error.message}`
    };
  }
}

// Individual handlers extract params and call internal functions
async function handleFileWrite(action: CladaAction): Promise<FileOpResult> {
  const { path, content } = action.parameters;
  
  try {
    
    // Create parent directories if needed
    const parentDir = dirname(path);
    const createdDirs = await ensureDirectoryExists(parentDir);
    
    // Write file
    const bytesWritten = await writeFileInternal(path, content);
    
    const result: FileOpResult = {
      success: true,
      data: {
        path,
        bytesWritten
      }
    };
    
    if (createdDirs.length > 0) {
      result.data.createdDirs = createdDirs;
    }
    
    return result;
    
  } catch (error) {
    return {
      success: false,
      error: formatNodeError(error, path, 'file_write')
    };
  }
}
```

## Extracted Pure Functions Needed

### Core File Operations
- `writeFileInternal(path: string, content: string): Promise<number>` - Returns bytes written
- `fileExists(path: string): Promise<boolean>` - Check if file exists
- `ensureDirectoryExists(path: string): Promise<string[]>` - Creates dirs, returns created paths
- `formatNodeError(error: any, path: string, operation: string): string` - Format Node errors consistently ✅

### Path Utilities (Pure)
- `getParentDirectory(path: string): string` - Extract parent dir from path ✅
- `normalizePath(path: string): string` - Normalize path separators
- `getCreatedDirectories(targetPath: string, existingPaths: Set<string>): string[]` - Determine which dirs were created

### Content Utilities (Pure)
- `getByteLength(content: string): number` - Calculate UTF-8 byte length ✅
- `replaceText(content: string, oldText: string, newText: string, count?: number): {result: string, replacements: number}` - Replace text occurrences ✅

### Directory Listing (Pure)
- `formatDirEntry(name: string, stats: Stats): DirEntry` - Format stat info into our type

## Implementation Progress

### Completed Pure Functions
1. ✅ `getParentDirectory` - Path extraction
2. ✅ `getByteLength` - UTF-8 byte counting
3. ✅ `replaceText` - Text replacement with count
4. ✅ `formatNodeError` - Error message formatting

## Implementation Order

1. **Path utilities** (pure functions, easy to test)
2. **Content utilities** (pure functions)
3. **Core file operations** (async, need mocking for tests)
4. **Action handlers** (integrate everything)

## Error Handling Strategy

- All internal functions throw native errors
- Handlers catch and format errors into FileOpResult
- Preserve original error codes (ENOENT, EACCES, etc.)
- Add context about what operation was attempted

## Test Data Structure Ideas

For pure functions:
```json
{
  "cases": [
    {
      "name": "extract parent from simple path",
      "input": ["/tmp/test.txt"],
      "expected": "/tmp"
    }
  ]
}
```

For async functions (need to mock fs):
```json
{
  "cases": [
    {
      "name": "file exists returns true",
      "input": ["/tmp/exists.txt"],
      "mockFs": {
        "/tmp/exists.txt": "content"
      },
      "expected": true
    }
  ]
}
```

## Notes

- Integration tests show we need to handle:
  - Creating parent directories automatically
  - Proper error messages matching Node.js format
  - Byte counting for content
  - Permission errors
=== END FILE: ./proj/comp/fs-ops/doc/DESIGN_TEMP.md ===

=== START FILE: ./proj/comp/fs-ops/doc/TODO.md ===
Ambiguous file_replace_text behavior:

- What happens if old_text appears multiple times but count=1? Which occurrence gets replaced?
    
    this results in an error!

What if old_text doesn't exist? Silent success or error?


    error!
=== END FILE: ./proj/comp/fs-ops/doc/TODO.md ===

=== START FILE: ./proj/comp/fs-ops/doc/ABSTRACT.md ===
# File System Operations

Executes file and directory operations from parsed SHAM actions, providing consistent error handling and operation results for LLM feedback.

## Overview

The fs-ops component is the primary executor for file system operations in clada. It receives parsed CladaAction objects from the sham-action-parser and performs the requested file system operations, returning standardized results that include success status, operation-specific data, and detailed error information when operations fail.

The component handles all file-related SHAM actions including file creation, editing, deletion, and reading, as well as directory operations and search functionality. It automatically handles common scenarios like creating parent directories for new files and provides detailed error messages that help the LLM understand why operations failed.

Each operation is designed to be atomic and independent, with no shared state between operations. This ensures predictable behavior and makes it easy for the LLM to reason about the effects of each action.
=== END FILE: ./proj/comp/fs-ops/doc/ABSTRACT.md ===

=== START FILE: ./proj/comp/fs-ops/doc/ARCH.md ===
# fs-ops Architecture

## Design Philosophy

**Defensive Operations with Clear Errors**: Every operation should handle common failure cases gracefully and return descriptive errors that help the LLM understand what went wrong.

## Key Design Decisions

### Parent Directory Creation
- `file_write` automatically creates parent directories.  creates parent directory if it doesn't exist

### Text Replacement Strategy  
- Use exact string matching for `file_replace_text`
- Count parameter limits replacements (default: 1)
- Return actual number of replacements made
- No regex support (keep it simple, predictable)

### Error Handling
- Never throw - return errors in result object
- Include original error codes (ENOENT, EACCES)
- Add context about what operation was attempted
- Preserve stack traces for debugging

### Path Resolution
- All paths must be absolute (validated by parser)
- No path traversal validation (security is out of scope for v1)
- Symlinks followed transparently

### Directory Operations
- `dir_delete` only removes empty directories
- No recursive deletion option (safety)
- `ls` returns flat listing with type info

### Search Operations
- `grep` uses simple substring matching
- Include patterns use glob syntax
- Results include line numbers
- Large file handling: streaming for files >10MB

## Performance Considerations

- File operations are synchronous from caller perspective
- No caching of file contents
- No watch/monitor capabilities
- Each operation is independent

## Encoding

- All text files assumed UTF-8
- Binary files not supported in v1
- Line endings preserved as-is

## Limits

- Max file size: 10MB (from unified-design.yaml)
- No limit on number of operations
- No timeout on individual operations

## Future Considerations

- Batch operations for efficiency
- Binary file support
- File watching/monitoring
- Atomic write operations (write to temp, rename)
- Path validation against allowlist
=== END FILE: ./proj/comp/fs-ops/doc/ARCH.md ===

=== START FILE: ./proj/comp/fs-ops/src/formatNodeError.ts ===
/**
 * Format Node.js filesystem errors into consistent error messages
 * @param error - The error object from Node.js
 * @param path - The file path involved in the operation
 * @param operation - The operation that was attempted
 * @returns Formatted error message string
 */
export function formatNodeError(error: any, path: string, operation: string): string {
  // Node.js errors have a code property
  if (error.code) {
    switch (error.code) {
      case 'ENOENT':
        return `ENOENT: no such file or directory, ${operation} '${path}'`;
      case 'EEXIST':
        return `EEXIST: file already exists, ${operation} '${path}'`;
      case 'EACCES':
        return `EACCES: permission denied, ${operation} '${path}'`;
      case 'EISDIR':
        return `EISDIR: illegal operation on a directory, ${operation} '${path}'`;
      case 'ENOTDIR':
        return `ENOTDIR: not a directory, ${operation} '${path}'`;
      case 'ENOTEMPTY':
        return `ENOTEMPTY: directory not empty, ${operation} '${path}'`;
      default:
        return `${error.code}: ${error.message}`;
    }
  }
  
  // Fallback for non-Node errors
  return error.message || `Unknown error during ${operation} on '${path}'`;
}
=== END FILE: ./proj/comp/fs-ops/src/formatNodeError.ts ===

=== START FILE: ./proj/comp/fs-ops/src/getParentDirectory.ts ===
import { dirname, sep } from 'path';

/**
 * Extract parent directory from a file path
 * Handles both Unix and Windows style paths
 * @param filePath - Absolute path to file or directory
 * @returns Parent directory path
 */
export function getParentDirectory(filePath: string): string {
  // Check if it's a Windows path (C:\ or C:/)
  const isWindowsPath = /^[A-Za-z]:[\\/]/.test(filePath);
  
  if (isWindowsPath) {
    // Handle Windows paths manually
    const normalized = filePath.replace(/\//g, '\\');
    const lastSep = normalized.lastIndexOf('\\');
    
    // Handle root paths like C:\
    if (lastSep <= 2) {
      return normalized.substring(0, 3); // Return C:\ 
    }
    
    return normalized.substring(0, lastSep);
  }
  
  // Use native dirname for Unix paths
  return dirname(filePath);
}
=== END FILE: ./proj/comp/fs-ops/src/getParentDirectory.ts ===

=== START FILE: ./proj/comp/fs-ops/src/getByteLength.ts ===
/**
 * Calculate UTF-8 byte length of a string
 * @param content - String content to measure
 * @returns Number of bytes in UTF-8 encoding
 */
export function getByteLength(content: string): number {
  return Buffer.byteLength(content, 'utf8');
}
=== END FILE: ./proj/comp/fs-ops/src/getByteLength.ts ===

=== START FILE: ./proj/comp/fs-ops/src/fileSystemUtils.ts ===
import { writeFile, mkdir, stat } from 'fs/promises';
import { dirname } from 'path';

/**
 * Check if a file exists
 * @param path - File path to check
 * @returns true if file exists, false otherwise
 */
export async function fileExists(path: string): Promise<boolean> {
  try {
    await stat(path);
    return true;
  } catch {
    return false;
  }
}

/**
 * Create directory and all parent directories if they don't exist
 * @param dirPath - Directory path to create
 * @returns Array of directories that were created (not those that already existed)
 */
export async function ensureDirectoryExists(dirPath: string): Promise<string[]> {
  const created: string[] = [];
  const parts = dirPath.split('/').filter(Boolean);
  
  // Handle root for Unix paths
  let currentPath = dirPath.startsWith('/') ? '' : '.';
  
  for (const part of parts) {
    currentPath = currentPath + '/' + part;
    
    try {
      await mkdir(currentPath);
      created.push(currentPath);
    } catch (err: any) {
      // EEXIST is fine - directory already exists
      if (err.code !== 'EEXIST') {
        throw err;
      }
    }
  }
  
  return created;
}

/**
 * Write file content and return number of bytes written
 * @param path - File path to write to
 * @param content - Content to write (UTF-8)
 * @returns Number of bytes written
 */
export async function writeFileInternal(path: string, content: string): Promise<number> {
  await writeFile(path, content, 'utf8');
  return Buffer.byteLength(content, 'utf8');
}
=== END FILE: ./proj/comp/fs-ops/src/fileSystemUtils.ts ===

=== START FILE: ./proj/comp/fs-ops/src/replaceText.ts ===
/**
 * Replace occurrences of text in content with optional count limit
 * @param content - Original content
 * @param oldText - Text to find and replace
 * @param newText - Replacement text
 * @param count - Maximum replacements (default: replace all)
 * @returns Object with result string and number of replacements made
 */
export function replaceText(
  content: string, 
  oldText: string, 
  newText: string, 
  count?: number
): { result: string; replacements: number } {
  if (oldText === '') {
    return { result: content, replacements: 0 };
  }

  let result = content;
  let replacements = 0;
  let startIndex = 0;

  while (true) {
    const index = result.indexOf(oldText, startIndex);
    if (index === -1) break;
    
    if (count !== undefined && replacements >= count) break;
    
    result = result.slice(0, index) + newText + result.slice(index + oldText.length);
    startIndex = index + newText.length;
    replacements++;
  }

  return { result, replacements };
}
=== END FILE: ./proj/comp/fs-ops/src/replaceText.ts ===

=== START FILE: ./proj/comp/fs-ops/src/index.ts ===
/**
 * fs-ops - File system operations executor for clada
 * 
 * Handles all file and directory operations from parsed SHAM actions
 */

import type { CladaAction } from '../../sham-action-parser/src/index.js';
import { formatNodeError } from './formatNodeError.js';
import { getParentDirectory } from './getParentDirectory.js';
import { fileExists, ensureDirectoryExists, writeFileInternal } from './fileSystemUtils.js';

export interface FileOpResult {
  success: boolean;
  data?: any;
  error?: string;
}

export class FileOpError extends Error {
  constructor(
    message: string,
    public code: string,
    public path?: string,
    public operation?: string
  ) {
    super(message);
    this.name = 'FileOpError';
  }
}

/**
 * Execute a file system operation from a parsed SHAM action
 * Never throws - all errors returned in result
 */
export async function executeFileOperation(action: CladaAction): Promise<FileOpResult> {
  try {
    const handler = actionHandlers[action.action];
    
    if (!handler) {
      return {
        success: false,
        error: `Unknown action: ${action.action}`
      };
    }
    
    return await handler(action);
    
  } catch (error: any) {
    // This should never happen - handlers should catch their own errors
    return {
      success: false,
      error: `Unexpected error in executeFileOperation: ${error.message}`
    };
  }
}

/**
 * Handle file_write action - writes/creates/overwrites a file with content
 * Automatically creates parent directories if needed
 */
async function handleFileWrite(action: CladaAction): Promise<FileOpResult> {
  const { path, content } = action.parameters;
  
  try {
    
    // Create parent directories if needed
    const parentDir = getParentDirectory(path);
    const createdDirs = await ensureDirectoryExists(parentDir);
    
    // Write file
    const bytesWritten = await writeFileInternal(path, content);
    
    const result: FileOpResult = {
      success: true,
      data: {
        path,
        bytesWritten
      }
    };
    
    // Add createdDirs only if we actually created any
    if (createdDirs.length > 0) {
      result.data.createdDirs = createdDirs;
    }
    
    return result;
    
  } catch (error: any) {
    return {
      success: false,
      error: formatNodeError(error, path, 'file_write')
    };
  }
}

// Internal function stubs for each operation

async function createFile(path: string, content: string): Promise<void> {
  throw new Error('Not implemented');
}

async function writeFile(path: string, content: string): Promise<void> {
  throw new Error('Not implemented');
}

async function replaceTextInFile(path: string, oldText: string, newText: string, count?: number): Promise<number> {
  throw new Error('Not implemented');
}

async function deleteFile(path: string): Promise<void> {
  throw new Error('Not implemented');
}

async function moveFile(oldPath: string, newPath: string): Promise<void> {
  throw new Error('Not implemented');
}

async function readFileContent(path: string): Promise<string> {
  throw new Error('Not implemented');
}

async function createDirectory(path: string): Promise<void> {
  throw new Error('Not implemented');
}

async function deleteDirectory(path: string): Promise<void> {
  throw new Error('Not implemented');
}

interface DirEntry {
  name: string;
  type: 'file' | 'directory';
  size: number;
  modified: Date;
}

async function listDirectory(path: string): Promise<DirEntry[]> {
  throw new Error('Not implemented');
}

interface GrepResult {
  file: string;
  line_number: number;
  line: string;
}

async function searchFiles(pattern: string, path: string, include?: string): Promise<GrepResult[]> {
  throw new Error('Not implemented');
}

async function globFiles(pattern: string, basePath: string): Promise<string[]> {
  throw new Error('Not implemented');
}

// Action handler mapping
const actionHandlers: Record<string, (action: CladaAction) => Promise<FileOpResult>> = {
  'file_write': handleFileWrite,
  'file_replace_text': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'file_delete': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'file_move': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'file_read': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'dir_create': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'dir_delete': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'ls': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'grep': async (action) => {
    return { success: false, error: 'Not implemented' };
  },
  'glob': async (action) => {
    return { success: false, error: 'Not implemented' };
  }
};
=== END FILE: ./proj/comp/fs-ops/src/index.ts ===

=== START FILE: ./proj/doc/API.md ===
# Component: clada

## Component Type
standard

## Dependencies

```yaml
dependencies:
  proj/comp/sham-action-parser:  # [IMPLEMENTED]
    functions: [parseShamResponse]
    types: [ParseResult, CladaAction, ParseError]
  
  proj/comp/fs-ops:              # [PLANNED]
    functions: [executeFileOperation]
    types: [FileOpResult]
  
  proj/comp/exec:                # [PLANNED]
    functions: [executeCommand]
    types: [ExecResult]
  
  proj/comp/git-tx:              # [PLANNED]
    functions: [ensureCleanRepo, commitChanges]
    types: [GitError]
  
  proj/comp/context:             # [PLANNED]
    functions: [addPath, removePath, listPaths, clearContext]
    types: [ContextError]
  
  external/nesl-js:
    functions: [parseSham]
    types: [Block, ParseResult, ParseError]
```

## Exports

```yaml
exports:
  classes:
    Clada:
      methods: [execute]
  types: 
    - ExecutionResult
    - ActionResult  
    - ParseError
    - CladaOptions
```

### Clada (class)
- **Purpose**: Main orchestrator executing SHAM blocks from LLM output
- **Constructor**: `new Clada(options?: CladaOptions)`
- **State**: Maintains working directory and context set across execute() calls

### execute
- **Signature**: `async execute(llmOutput: string): Promise<ExecutionResult>`
- **Purpose**: Parse and execute all SHAM blocks in LLM output, commit results
- **Process**: 
  1. Ensure clean git state
  2. Parse SHAM blocks
  3. Convert to actions
  4. Execute all valid actions
  5. Commit changes with summary
- **Throws**: Never - all errors captured in ExecutionResult
- **Test-data**: `test-data/execute/` [PLANNED]

### ExecutionResult (type)
```typescript
interface ExecutionResult {
  success: boolean              // False if any action failed
  totalBlocks: number          // Count of SHAM blocks found
  executedActions: number      // Count of actions attempted
  results: ActionResult[]      // All execution results
  parseErrors: ParseError[]    // SHAM parsing errors
  gitCommit?: string          // Commit SHA if successful
  fatalError?: string         // Git or system failure
}
```

### ActionResult (type)
```typescript
interface ActionResult {
  seq: number                  // Execution order
  blockId: string             // SHAM block ID
  action: string              // Action type
  params: Record<string, any> // Input parameters
  success: boolean
  error?: string              // Error message if failed
  data?: any                  // Action-specific output
}
```

### ParseError (type)
```typescript
interface ParseError {
  blockId?: string            // If error is block-specific
  error: ShamError            // From parser
}
```

### CladaOptions (type)
```typescript
interface CladaOptions {
  repoPath?: string           // Default: process.cwd()
  gitCommit?: boolean         // Default: true
}
```

## Internal Architecture

### Execution Flow
```
execute(llmOutput)
  → parseSHAM(llmOutput) → ShamParseResult
  → for each valid block:
    → convertToActions(block) → CladaAction[]
    → for each action:
      → route to appropriate executor
      → capture result
  → commitChanges(results)
  → return ExecutionResult
```

### Action Routing
- file_* → fs-ops
- dir_* → fs-ops
- exec → exec
- context_* → context
- ls, grep, glob → fs-ops (read operations)

### Error Handling
- Parser errors: Skip block, record error
- Conversion errors: Skip action, record error
- Execution errors: Continue execution, record error
- Git errors: Fatal, abort with fatalError
=== END FILE: ./proj/doc/API.md ===

=== START FILE: ./proj/doc/TODO.md ===

Issues revealed by execute.md test design:

Missing gitCommit field in expected results
Context operations not tested - are they SHAM actions?
Git state check not tested - what if dirty repo?
Directory creation for file operations unclear
=== END FILE: ./proj/doc/TODO.md ===

=== START FILE: ./proj/doc/ARCH.md ===
# Clada Architecture

## Core Design Decisions

### Transaction Model
- **No automatic rollback** - All operations commit, including failures
- **Failures are data** - LLM needs failure feedback for next steps
- **Forward-only progress** - Cheaper than regenerating responses
- **Manual rollback only** - Human-initiated via git commands
- **Boundary**: One git commit per `execute()` call
- **API**: Explicit transaction management (details TBD)

### SHAM Processing Pipeline
1. SHAM parser (external npm) → AST
2. AST → Action objects (sham-ast-converter)
3. Actions → Execution → Results

### SHAM AST Structure
```typescript
interface ShamParseResult {
  blocks: ShamBlock[]
  errors: ShamError[]
}

interface ShamBlock {
  id: string           // 3-char SHA-256
  properties: {
    action: string     // Maps to tool name (e.g., "file_write")
    [key: string]: any // Tool-specific parameters
  }
  startLine: number
  endLine: number
}

interface ShamError {
  code: string         // e.g., "DUPLICATE_KEY"
  line: number
  column: number
  length: number
  blockId: string
  content: string
  context: string
  message: string
}
```

### Error Propagation Strategy
- **Parser errors**: Skip blocks with parser errors, execute valid blocks only
- **Validation errors**: Skip invalid actions, execute valid ones
- **Execution errors**: Continue with remaining actions
- **Result**: Complete execution log with successes and failures

### Action Mapping
- SHAM `action` property maps directly to tool names from unified-design.yaml
- Use canonical names: `file_write`, `exec`, etc.

### Context Management
- **V1**: Simple `Set<string>` of file paths
- **Storage**: In-memory only, no persistence across sessions
- **V2 Future**: Sub-file references (lines, functions, sections)

### Execution Model
- **Synchronous**: All operations block until complete
- **CWD Management**: Session-based working directory
  - Default: Repository root
  - Each exec can override with `cwd` parameter
  - CWD persists within session, not across transactions
- **Results Format**: Flat array with sequence numbers
```typescript
interface ActionResult {
  seq: number          // Execution order
  blockId: string      // SHAM block ID
  action: string       // Action type
  params: any          // Input parameters
  success: boolean
  error?: string       // Error message if failed
  data?: any           // Action-specific output (stdout, content, etc.)
}
```

### Security Model (V1)
- **None**: Full filesystem access
- **No validation**: Any path allowed
- **No sandboxing**: Direct execution
- **V2 Future**: Path allowlisting per unified-design.yaml

## Component Structure
```
clada/
├── proj/
│   ├── comp/
│   │   ├── sham-ast-converter/  # AST → Actions
│   │   ├── fs-ops/              # File/directory operations
│   │   ├── exec/                # Command execution
│   │   ├── git-tx/              # Git transaction management
│   │   └── context/             # Working set management
│   └── doc/
│       ├── API.md               # Main orchestrator API
│       ├── ARCH.md              # This document
│       └── ABSTRACT.md          # Project overview
```

## Implementation Priorities
1. `sham-ast-converter` - Cannot test without this
2. `fs-ops` - Core functionality
3. `exec` - Command execution
4. `git-tx` - Transaction wrapper
5. `context` - Working set (may be simple enough to inline)

## Open Questions

### Critical
1. **SHAM parser package**: `nesl-js` from `github:nesl-lang/nesl-js`
   - Import: `const { parseSHAM } = require('nesl-js')`
2. **Transaction API**: Single `execute()` method processes SHAM block array

### Design
1. **Parser error handling**: Execute blocks with parser errors or skip?
2. **Git conflict handling**: How to handle conflicts during manual rollback?
3. **Concurrent access**: Multiple clada instances on same repo?
4. **Partial failure behavior**: Continue executing after first failure or abort?

### Future
1. **Context references**: Syntax for line ranges and functions
2. **Execution isolation**: Container/VM strategy for V2
3. **Streaming results**: Return results as actions complete or batch at end?

## Design Rationale

### Why No Automatic Rollback
Traditional transaction systems rollback on failure to maintain consistency. Clada explicitly rejects this because:
1. **LLM responses are expensive** - Regenerating costs time and money
2. **Partial success is informative** - LLM learns from failures
3. **Git preserves history** - Can always manually revert
4. **Forward progress over perfection** - Incremental improvement model

### Why Synchronous Execution
1. **Deterministic results** - LLM needs to know exact outcomes
2. **Sequential dependencies** - Later actions may depend on earlier ones
3. **Simpler implementation** - No async state management
4. **Git compatibility** - Git operations are inherently synchronous

### Why In-Memory Context
1. **Session isolation** - Each LLM conversation is independent
2. **No persistence complexity** - No file format versioning
3. **Git is the source of truth** - Files on disk matter, not context
4. **Quick reset** - New session = clean slate
=== END FILE: ./proj/doc/ARCH.md ===

=== START FILE: ./unified-design.yaml ===
# AI Coder Tools Schema - Unified Design

# Clada executes filesystem and runtime commands embedded in LLM output using SHAM syntax. It provides deterministic filesystem access and shell command execution for LLM coding agents.

# SHAM syntax example:

SHAM_synatx_example: |
  ```sh sham
  #!SHAM [@three-char-SHA-256: k7m]
  action = "file_write"
  path = "/tmp/\"hello\".txt"
  content = <<'EOT_SHAM_k7m'
  Hello world!
  how are you?
  EOT_SHAM_k7m
  #!END_SHAM_k7m
  ```


tools:
  # File Operations
  file_write:
    type: write
    description: Create new file while creating any necessary parent dirs. overwrites if already exists
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
      content: {type: string, required: true}
    returns: {success: boolean, error?: string}
    
  file_replace_text:
    type: write
    description: Replace substring in file
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
      old_text: {type: string, required: true}
      new_text: {type: string, required: true}
      count: {type: integer, required: false, default: 1}
    returns: {success: boolean, replacements_made?: integer, error?: string}
    
  file_append:
    type: write
    description: Append to file
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
      content: {type: string, required: true}
    returns: {success: boolean, error?: string}
    
  file_delete:
    type: write
    description: Delete file
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
    
  file_move:
    type: write
    description: Move/rename file
    accessibility: [llm]
    parameters:
      old_path: {type: string, required: true, format: absolute_path}
      new_path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
    
  file_read:
    type: read
    description: Read file content (ephemeral)
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, content?: string, error?: string}
    
  # Directory Operations
  dir_create:
    type: write
    description: Create directory
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
    
  dir_delete:
    type: write
    description: Delete directory
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
    
  # Read Operations
  ls:
    type: read
    description: List directory contents
    accessibility: [llm]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: 
      success: boolean
      data:
        type: array
        items:
          name: string
          type: string  # file|directory
          size: integer
          modified: timestamp
      error: string
    
  grep:
    type: read
    description: Search pattern in files
    accessibility: [llm]
    parameters:
      pattern: {type: string, required: true}
      path: {type: string, required: true, format: absolute_path}
      include: {type: string, required: false}
    returns: 
      success: boolean
      data:
        type: array
        items:
          file: string
          line_number: integer
          line: string
      error: string
    
  glob:
    type: read
    description: Find files matching pattern
    accessibility: [llm]
    parameters:
      pattern: {type: string, required: true}
      base_path: {type: string, required: true, format: absolute_path}
    returns: 
      success: boolean
      data:
        type: array
        items: string
      error: string
    
  # Execution
  exec:
    type: dynamic
    description: Execute code
    accessibility: [llm]
    parameters:
      code: {type: string, required: true}
      lang: {type: enum, values: [python, javascript, bash, ruby], required: true}
      version: {type: string, required: false}
      cwd: {type: string, required: false, format: absolute_path}
    returns: {success: boolean, stdout?: string, stderr?: string, exit_code?: integer, error?: string}

  # Context Operations -- for much later.  dont do this until clada has been integrated into bigfoot, the ai llm coder
  context_add:
    type: meta
    description: Add item to working context (persistent)
    accessibility: [llm, user]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
      
  context_remove:
    type: meta
    description: Remove item from working context
    accessibility: [llm, user]
    parameters:
      path: {type: string, required: true, format: absolute_path}
    returns: {success: boolean, error?: string}
      
  context_list:
    type: meta
    description: List items in working context
    accessibility: [llm, user]
    parameters: {}
    returns: 
      success: boolean
      data:
        type: array
        items:
          path: string
          size: integer
      error: string
    
  context_prune:
    type: meta
    description: Remove unused items from working context
    accessibility: [llm, user]
    parameters: {}
    returns: {success: boolean, removed?: array of strings, error?: string}
    
  context_clear:
    type: meta
    description: Clear all working context items
    accessibility: [llm, user]
    parameters: {}
    returns: {success: boolean, error?: string}
    
  # Git Operations
  git_squash:
    type: git
    description: Squash commits
    slash_command: true
    parameters:
      mode: {type: enum, values: [auto_ai, ai_messages, hours, days, contiguous_only=true, msg_contains], required: true}
      message: {type: string, required: false}
      hours: {type: integer, required: false, when: "mode=hours"}
      days: {type: integer, required: false, when: "mode=days"}
      msg_target: {type: string, required: false, when: "mode=msg_contains"}
    returns: {success: boolean, error?: string}
      
  undo:
    type: git
    description: Undo last AI changes
    accessibility: [user]
    constraints: ["No changes since last AI operation"]
    parameters: {}
    returns: {success: boolean, error?: string}
    
  git_step_back:
    type: git
    description: Move to previous commit
    accessibility: [user]
    behavior: Stashes untracked changes
    parameters: {}
    returns: {success: boolean, stashed_files?: array of strings, error?: string}
    
  git_step_forward:
    type: git
    description: Move to next commit
    accessibility: [user]
    behavior: Attempts to pop stashed changes
    parameters: {}
    returns: {success: boolean, conflicts?: array of strings, error?: string}

# Transaction Management
transaction_model:
  strategy: operation_group
  conflict_detection:
    methods:
      - mtime comparison (fast but unreliable)
      - checksum comparison (slower but accurate)
      - git status check (catches git-tracked changes)
    timing:
      - Check immediately before operation group
      - Check after each write operation
      - Final check before commit
  implementation:
    - Begin: git commit current state
    - Execute: track all operations
    - Validate: check for external modifications
    - Success: git commit with summary
    - Failure: git reset --hard to start
  atomicity: none  # Git operations are NOT atomic at filesystem level
  
# Security Model
security:
  path_validation:
    type: allowlist
    allowed_roots:
      - /home/user/projects
      - /tmp/ai-coder
    blacklist_patterns:
      - .*\.ssh.*
      - .*\.git/config
      - /etc/.*
      - /sys/.*
      - /proc/.*
  canonicalization: required  # Resolve ../ and symlinks before checking
  
# System Configuration
config:
  encoding: utf-8
  line_endings: preserve  # Don't normalize
  max_file_size: 10485760  # 10MB
  git_auto_push: false  # Require explicit push
  commit_message_format: "AI: {operation_summary}"

TODO: |   
  Transaction Safety: The git-based transaction model has race conditions:

    Gap between "git commit" and first operation
    Non-atomic filesystem ops vs git state
=== END FILE: ./unified-design.yaml ===

=== START FILE: ./README.md ===
# 💚 clada
common llm actions desktop actuator

=== END FILE: ./README.md ===

=== START FILE: ./xd5_ref.md ===
# XD5 LLM Quick Reference

## Core Principle
Documentation maintains dependency graphs for deterministic context assembly. Initial dependencies are hypotheses - implementation discovers reality. The STOP protocol ensures documentation evolves to match actual dependencies.

## File Structure
```
<repo>/
└── proj/
    ├── doc/
    │   ├── API.md        # ⚠️ CRITICAL: All dependencies + exports
    │   ├── ABSTRACT.md   # 60-word purpose + 300-word overview
    │   └── ARCH.md       # Technical decisions, constraints
    ├── test-data/        # Test cases as JSON/MD files
    ├── test/             # Minimal harnesses loading test-data
    ├── test-intn/        # Integration tests for dependencies
    ├── src/              # Implementation
    └── comp/             # Sub-components (recursive) - do not need 'proj' dirs
```

## API.md Template
```markdown
# Component: {name}

## Component Type
standard | types-only

## Dependencies
[Provisional - updated via STOP protocol when implementation reveals actual needs]

Mark internal component status: [PLANNED], [IN-PROGRESS], or [IMPLEMENTED]
External dependencies do not need status markers.

```yaml
dependencies:
  # Initial hypothesis based on design
  proj/comp/payment:                                       # [PLANNED]
    functions: [validateCard, processRefund] # may change
    types: [PaymentResult, CardType]
    errors: [PaymentError]
  
  proj/comp/auth:                                          # [IMPLEMENTED]
    functions: [checkPermission, validateToken]
    types: [User, TokenPayload]
  
  proj/comp/logger:                                        # [IN-PROGRESS]
    functions: [logTransaction]  # Audit requirement
  
  proj/comp/payment-types: "*"  # Wildcard for types-only  # [IMPLEMENTED] 
  
  external/lodash:
    functions: [groupBy, mapValues]
  
  external/@stripe/stripe-js:
    types: [Stripe, PaymentIntent]
    functions: [loadStripe]
```

## Exports
[Structured YAML for dependency graph tooling, then prose descriptions]

```yaml
exports:
  functions: [functionName1, functionName2]
  types: [Type1, Type2, Type3]
  classes:
    ClassName:
      methods: [method1, method2]
  errors: [CustomError1, CustomError2]
```

### {functionName}
- **Signature**: `{functionName}(param: Type) -> ReturnType`
- **Purpose**: Single sentence.
- **Throws**: `{ErrorType}` when {condition}
- **Test-data**: `test-data/{path}/{functionName}.json` [PLANNED|IMPLEMENTED]



## Workflow

### Core Flow: Design → Test → Implement

1. **Write docs**: ABSTRACT.md → ARCH.md → API.md (provisional)
2. **Design tests**: E2E hypothesis → Decompose → Unit tests  
3. **Implement**: Discover real dependencies → Update docs → Complete code

### Test Authority & Evolution

**Tests Are Source of Truth (But Not Infallible)**
- Tests define what code SHOULD do
- During debug: ALWAYS fix code to match tests first
- Test errors discovered? Ask human: "I believe test X is incorrect because Y. Should I update it?"
- NEVER auto-modify tests while debugging
- Each test change needs explicit approval

### Detailed Flow

1. **E2E Test Hypothesis** - Write component test-data (expect evolution)
2. **Pseudocode** - Rough implementation to discover structure
3. **Extract Functions** - Identify & extract all pure functions
4. **Unit Tests** - Write test-data for each function
5. **Implement Functions** - Red/green/debug (fix code, not tests)
6. **Revise E2E Tests** - Align with discovered behavior (ask human)
7. **Wire Component** - Connect tested functions
8. **Debug E2E** - Fix code until green

**Debug Protocol**: Test fails? → Try fixing code → Still failing? → Consider test error → Request human approval for any test change

**If docs are wrong**: STOP → Update docs → Update tests → Continue



### Critical Implementation Rules

**Initial Docs Are Hypotheses**: 
- First API.md contains best guesses
- Dependencies WILL be wrong
- This is expected and healthy
- Discovery through implementation is the goal

**🛑 STOP Protocol**: When implementation reveals doc errors:
1. STOP immediately
2. Update API.md/ARCH.md
3. Continue with correct docs

**Test Immutability**: 
- Test harnesses = frozen after creation
- Test data = only change with human approval
- Fix code, not tests (unless explicitly approved)

**Dependency Updates**:
- Add to API.md as discovered
- Include transitive deps if needed for understanding
- External deps must be explicit

## Test Data Format
```json
{
  "cases": [
    {
      "name": "descriptive name",
      "input": [arg1, arg2],
      "expected": {result},
      "throws": "ErrorType"  // optional
    }
  ]
}
```

## Quick Checks

Before implementing:
- [ ] API.md declares all exports?
- [ ] Dependencies section updated?
- [ ] Test data files created?

During implementation:
- [ ] Tests fail first (red phase)?
- [ ] Docs match reality? (if not → STOP)
- [ ] All imports declared in API.md?

## Common Patterns

**Extract pure functions during pseudocode**:
```javascript
// Pseudocode reveals:
// extractedFn: validateInput(x) -> bool
// extractedFn: processData(data) -> result
```

**Types-only components**: No test/ or src/, only doc/

**Path conventions**: All relative to `<repo>/`
- Component: `proj/comp/{name}`
- Nested: `proj/comp/{parent}/comp/{child}`


# update 

- need to update this so that we save our pseudocde in some sort of documetnation, maybe temp documentation.  so if we implement the fucntiosn to unit test, we dont get confused later about how theyre supposed to be used.

- ideally, each extracted function unit-testable function would be in its own file.  for parallelism with the unit test files
=== END FILE: ./xd5_ref.md ===

=== START FILE: ./package.json ===
{
  "name": "clada",
  "version": "0.1.0",
  "description": "Common LLM Actions Desktop Actuator",
  "type": "module",
  "engines": {
    "node": ">=20.0.0"
  },
  "scripts": {
    "build": "tsc --noEmit",
    "dev": "tsx watch proj/src/index.ts",
    "start": "tsx proj/src/index.ts",
    "test": "vitest run",
    "test:watch": "vitest watch",
    "test:run": "vitest run",
    "typecheck": "tsc --noEmit",
    "lint": "eslint proj/**/*.ts",
    "lint:fix": "eslint proj/**/*.ts --fix"
  },
  "dependencies": {
    "js-yaml": "^4.1.0",
    "marked": "^12.0.0",
    "nesl-js": "github:nesl-lang/nesl-js"
  },
  "devDependencies": {
    "@types/js-yaml": "^4.0.9",
    "@types/node": "^20.11.0",
    "@typescript-eslint/eslint-plugin": "^7.0.0",
    "@typescript-eslint/parser": "^7.0.0",
    "eslint": "^8.56.0",
    "tsx": "^4.7.0",
    "typescript": "^5.3.3",
    "vitest": "^1.2.0"
  },
  "keywords": [
    "llm",
    "actions",
    "filesystem",
    "sham"
  ],
  "author": "",
  "license": "MIT"
}

=== END FILE: ./package.json ===

=== START FILE: ./.nvmrc ===
20.11.0
=== END FILE: ./.nvmrc ===

=== START FILE: ./scripts/checks/check-marked-types.ts ===
import { marked } from 'marked';
import type * as MarkedTypes from 'marked';

// Try to see what's available
console.log('marked keys:', Object.keys(marked));
console.log('marked.Tokens exists?', 'Tokens' in marked);

// The tokens are likely under a different export
const tokens = marked.lexer('# test\n```js\ncode\n```');
console.log('First token type:', tokens[0]?.type);
console.log('First token constructor:', tokens[0]?.constructor?.name);
=== END FILE: ./scripts/checks/check-marked-types.ts ===

=== START FILE: ./scripts/checks/check-nesl.js ===
import { parseSham } from 'nesl-js';
import * as nesl from 'nesl-js';

console.log('nesl-js exports:', Object.keys(nesl));
console.log('\nparseSham type:', typeof parseSham);

const result = parseSham(`#!SHAM [@three-char-SHA-256: abc]
action = "test"
#!END_SHAM_abc`);

console.log('\nResult:', JSON.stringify(result, null, 2));
console.log('\nResult type:', typeof result);
console.log('Result constructor:', result?.constructor?.name);
console.log('Blocks type:', Array.isArray(result?.blocks) ? 'array' : typeof result?.blocks);
=== END FILE: ./scripts/checks/check-nesl.js ===

=== START FILE: ./scripts/checks/check-marked.js ===
import { marked } from 'marked';

const md = `# Test
\`\`\`js
code here
\`\`\`
`;

const tokens = marked.lexer(md);
console.log('Token types:', tokens.map(t => ({
  type: t.type,
  hasText: 'text' in t,
  props: Object.keys(t)
})));
=== END FILE: ./scripts/checks/check-marked.js ===

=== START FILE: ./tsconfig.json ===
{
  "compilerOptions": {
    // Modern output settings
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "lib": ["ES2022"],
    
    // Strict type checking
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "strictBindCallApply": true,
    "strictPropertyInitialization": true,
    "noImplicitThis": true,
    "alwaysStrict": true,
    
    // Additional checks
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedIndexedAccess": true,
    
    // Output settings
    "outDir": "./dist",
    "rootDir": ".",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    
    // Module resolution
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "resolveJsonModule": true,
    "forceConsistentCasingInFileNames": true,
    
    // Path mapping for cleaner imports
    "baseUrl": "."
  },
  "include": [
    "proj/**/*.ts"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "**/test/**",
    "**/test-data/**"
  ]
}
=== END FILE: ./tsconfig.json ===

=== START FILE: ./eslint.config.js ===
import js from '@eslint/js';
import typescript from '@typescript-eslint/eslint-plugin';
import tsParser from '@typescript-eslint/parser';

export default [
  js.configs.recommended,
  {
    files: ['**/*.ts'],
    languageOptions: {
      parser: tsParser,
      parserOptions: {
        project: './tsconfig.json',
        ecmaVersion: 'latest',
        sourceType: 'module'
      }
    },
    plugins: {
      '@typescript-eslint': typescript
    },
    rules: {
      ...typescript.configs.recommended.rules,
      '@typescript-eslint/explicit-function-return-type': 'error',
      '@typescript-eslint/no-explicit-any': 'error',
      '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
      '@typescript-eslint/consistent-type-imports': 'error',
      '@typescript-eslint/no-non-null-assertion': 'error'
    }
  }
];
=== END FILE: ./eslint.config.js ===

=== START FILE: ./vitest.config.ts ===
import { defineConfig } from 'vitest/config';
import path from 'path';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    include: ['proj/**/*.test.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'proj/test/',
        '**/*.test.ts'
      ]
    }
  },
  resolve: {
    alias: {}
  }
});
=== END FILE: ./vitest.config.ts ===
